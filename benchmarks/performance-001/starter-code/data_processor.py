"""
Data Processor - Finds duplicate entries and generates statistics

This module processes log data to find duplicate user sessions and
compute session statistics. It's used for analyzing user behavior patterns.
"""

import re
from typing import List, Dict, Tuple


class LogProcessor:
    """Processes log entries to find duplicates and compute statistics."""

    def __init__(self):
        self.logs = []

    def load_logs(self, log_entries: List[str]) -> None:
        """Load log entries for processing."""
        self.logs = log_entries

    def find_duplicate_sessions(self) -> List[Tuple[str, List[int]]]:
        """
        Find all duplicate user sessions in the logs.

        Returns:
            List of tuples (user_id, [line_numbers]) for users with duplicate sessions
        """
        duplicates = []

        # Parse each log entry to extract user_id
        for i in range(len(self.logs)):
            match = re.search(r'user_id=(\w+)', self.logs[i])
            if match:
                user_id = match.group(1)

                # Check if this user_id appears elsewhere (O(n²) comparison)
                line_numbers = []
                for j in range(len(self.logs)):
                    match2 = re.search(r'user_id=(\w+)', self.logs[j])
                    if match2 and match2.group(1) == user_id:
                        line_numbers.append(j)

                # Only include if there are duplicates
                if len(line_numbers) > 1:
                    # Check if we already added this user
                    already_added = False
                    for existing_user, _ in duplicates:
                        if existing_user == user_id:
                            already_added = True
                            break

                    if not already_added:
                        duplicates.append((user_id, line_numbers))

        return duplicates

    def compute_session_stats(self) -> Dict[str, int]:
        """
        Compute session duration statistics for each user.

        Returns:
            Dictionary mapping user_id to total session time in seconds
        """
        stats = {}

        # Process each log entry
        for log in self.logs:
            # Extract user_id and duration (repeated regex matching)
            user_match = re.search(r'user_id=(\w+)', log)
            duration_match = re.search(r'duration=(\d+)', log)

            if user_match and duration_match:
                user_id = user_match.group(1)
                duration = int(duration_match.group(1))

                # Sum up durations for each user (inefficient repeated lookups)
                if user_id in stats:
                    stats[user_id] = stats[user_id] + duration
                else:
                    stats[user_id] = duration

        return stats

    def get_top_users(self, stats: Dict[str, int], n: int = 10) -> List[Tuple[str, int]]:
        """
        Get top N users by session time.

        Args:
            stats: Dictionary of user_id -> total_time
            n: Number of top users to return

        Returns:
            List of (user_id, total_time) tuples, sorted by time descending
        """
        # Inefficient bubble sort instead of using built-in sort
        items = list(stats.items())

        # Bubble sort by session time (O(n²))
        for i in range(len(items)):
            for j in range(len(items) - 1 - i):
                if items[j][1] < items[j + 1][1]:
                    # Swap
                    temp = items[j]
                    items[j] = items[j + 1]
                    items[j + 1] = temp

        return items[:n]

    def process_all(self) -> Dict:
        """
        Run full analysis pipeline.

        Returns:
            Dictionary with duplicates and top users
        """
        duplicates = self.find_duplicate_sessions()
        stats = self.compute_session_stats()
        top_users = self.get_top_users(stats)

        return {
            'duplicates': duplicates,
            'stats': stats,
            'top_users': top_users
        }


def generate_test_logs(num_users: int = 1000, entries_per_user: int = 5) -> List[str]:
    """Generate test log data."""
    logs = []
    for user_num in range(num_users):
        user_id = f"user{user_num:04d}"
        for entry_num in range(entries_per_user):
            duration = (user_num + entry_num) % 100 + 10
            logs.append(
                f"[2024-01-{(entry_num % 28) + 1:02d}] session_start user_id={user_id} duration={duration}s status=active"
            )
    return logs


if __name__ == "__main__":
    # Demo usage
    processor = LogProcessor()
    logs = generate_test_logs(num_users=500, entries_per_user=3)
    processor.load_logs(logs)

    print("Processing logs...")
    import time
    start = time.time()
    result = processor.process_all()
    elapsed = time.time() - start

    print(f"\nProcessed {len(logs)} log entries in {elapsed:.2f} seconds")
    print(f"Found {len(result['duplicates'])} users with duplicate sessions")
    print(f"\nTop 5 users by session time:")
    for user_id, total_time in result['top_users'][:5]:
        print(f"  {user_id}: {total_time}s")
