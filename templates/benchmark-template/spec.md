# [Benchmark Name] - Specification

## Objective

[Clear one-sentence description of what the AI must accomplish]

## Background

[Context and background information needed to understand the task]

## Requirements

### Functional Requirements
1. [Requirement 1]
2. [Requirement 2]
3. [Requirement 3]

### Technical Constraints
- [Constraint 1]
- [Constraint 2]
- [Constraint 3]

### Quality Requirements
- All existing tests must pass
- Code must follow style guidelines (linter passes)
- [Other quality requirements]

## Success Criteria

The implementation will be considered successful when:
1. [Criterion 1 - must be verifiable]
2. [Criterion 2 - must be verifiable]
3. [Criterion 3 - must be verifiable]

## Deliverables

1. [Deliverable 1]
2. [Deliverable 2]
3. [Deliverable 3]

## Evaluation

Your submission will be scored on:
- [Component 1]: [weight]% - [description]
- [Component 2]: [weight]% - [description]
- [Component 3]: [weight]% - [description]

See verification/verify.sh for automated scoring implementation.
